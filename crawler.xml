<?xml version="1.0" encoding="UTF-8"?>
<root>
	<!-- user-agent for all spider -->
	<user-agent>
		<item
			name="Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.835.163 Safari/535.1"></item>
		<item
			name="Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0) Gecko/20100101 Firefox/6.0"></item>
		<item
			name="Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50"></item>
		<item
			name="Opera/9.80 (Windows NT 6.1; U; zh-cn) Presto/2.9.168 Version/11.50"></item>
		<item
			name="Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 2.0.50727; SLCC2; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; InfoPath.3; .NET4.0C; Tablet PC 2.0; .NET4.0E)"></item>
		<item
			name="Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; InfoPath.3)"></item>
		<item
			name="Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; GTB7.0)"></item>
		<item
			name="Mozilla/5.0 (Windows; U; Windows NT 6.1; ) AppleWebKit/534.12 (KHTML, like Gecko) Maxthon/3.0 Safari/534.12"></item>
		<item
			name="Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; InfoPath.3; .NET4.0C; .NET4.0E)"></item>
		<item
			name="Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.41 Safari/535.1 QQBrowser/6.9.11079.201"></item>
	</user-agent>
	<proxy> 


	</proxy>
	<crawler-common>
		<!-- all cache file,result report etc. default is user.dir/data -->
		<data-path></data-path>
		<!-- spider thread num. default is 1 -->
		<thread-num>20</thread-num>
		<!-- one url max queue retry num. default is 1 -->
		<cycle-retry-times>2</cycle-retry-times>
		<!-- in one thread max interval between two request. default is 6000ms -->
		<sleep-time>5000</sleep-time>
		<!-- max time before request is terminate. default is 5000ms -->
		<time-out>10000</time-out>
		<!-- use file urls.1: true 0:false default is 0 -->
		<use-cached-queue>0</use-cached-queue>
		<!-- use proxy.1: true 0:false default is 0 -->
		<use-proxy>1</use-proxy>
		<!-- when request is finsih spider restart 1:true 0:false default is 0 -->
		<auto-restart>0</auto-restart>
		<!-- spider which to start, can't empty or program can't start -->
		<spider-name>PriceCtripSpider</spider-name>
		<!-- proxy ip get address -->
		<proxy-get-address>http://erwx.daili666.com/ip/?tid=559566142973866</proxy-get-address>
		<!-- proxy retry time -->
		<proxy-retry>1</proxy-retry>
		<!--ahead-day defaule:30 -->
		<ahead-day>30</ahead-day>		
	</crawler-common>
</root>